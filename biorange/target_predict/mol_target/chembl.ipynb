{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import time\n",
    "import zlib\n",
    "from typing import Any, Dict, Generator, List, Optional, Union\n",
    "from urllib.parse import parse_qs, urlencode, urlparse\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter, Retry\n",
    "\n",
    "from biorange.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Constants\n",
    "POLLING_INTERVAL = 3\n",
    "API_URL = \"https://rest.uniprot.org\"\n",
    "\n",
    "# Retry strategy for requests\n",
    "retries = Retry(total=5, backoff_factor=0.25, status_forcelist=[500, 502, 503, 504])\n",
    "session = requests.Session()\n",
    "session.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "\n",
    "\n",
    "class ChEMBLTargetScraper:\n",
    "    def __init__(self):\n",
    "        self.session = session\n",
    "        self.all_predictions = pd.DataFrame()  # 初始化用于存储所有预测结果的DataFrame\n",
    "\n",
    "    def check_response(self, response: requests.Response) -> None:\n",
    "        try:\n",
    "            response.raise_for_status()\n",
    "        except requests.HTTPError as e:\n",
    "            logger.error(f\"HTTPError: {e.response.json()}\")\n",
    "            raise\n",
    "\n",
    "    def submit_id_mapping(self, from_db: str, to_db: str, ids: List[str]) -> str:\n",
    "        response = self.session.post(\n",
    "            f\"{API_URL}/idmapping/run\",\n",
    "            data={\"from\": from_db, \"to\": to_db, \"ids\": \",\".join(ids)},\n",
    "            timeout=600,\n",
    "        )\n",
    "        self.check_response(response)\n",
    "        return response.json()[\"jobId\"]\n",
    "\n",
    "    def get_next_link(self, headers: Dict[str, str]) -> Optional[str]:\n",
    "        if \"Link\" in headers:\n",
    "            match = re.match(r'<(.+)>; rel=\"next\"', headers[\"Link\"])\n",
    "            return match.group(1) if match else None\n",
    "        return None\n",
    "\n",
    "    def check_id_mapping_results_ready(self, job_id: str) -> bool:\n",
    "        while True:\n",
    "            response = self.session.get(f\"{API_URL}/idmapping/status/{job_id}\")\n",
    "            self.check_response(response)\n",
    "            status = response.json().get(\"jobStatus\")\n",
    "            if status == \"RUNNING\":\n",
    "                logger.info(f\"Retrying in {POLLING_INTERVAL}s\")\n",
    "                time.sleep(POLLING_INTERVAL)\n",
    "            elif status:\n",
    "                raise Exception(status)\n",
    "            else:\n",
    "                return bool(\n",
    "                    response.json().get(\"results\") or response.json().get(\"failedIds\")\n",
    "                )\n",
    "\n",
    "    def get_batch(\n",
    "        self, batch_url: str, file_format: str, compressed: bool\n",
    "    ) -> Generator[Union[Dict[str, Any], List[str]], None, None]:\n",
    "        while batch_url:\n",
    "            response = self.session.get(batch_url)\n",
    "            self.check_response(response)\n",
    "            yield self.decode_results(response, file_format, compressed)\n",
    "            batch_url = self.get_next_link(response.headers)\n",
    "\n",
    "    def combine_batches(\n",
    "        self,\n",
    "        all_results: Union[Dict[str, Any], List[str]],\n",
    "        batch_results: Union[Dict[str, Any], List[str]],\n",
    "        file_format: str,\n",
    "    ) -> Union[Dict[str, Any], List[str]]:\n",
    "        if file_format == \"json\":\n",
    "            for key in (\"results\", \"failedIds\"):\n",
    "                if key in batch_results:\n",
    "                    all_results[key].extend(batch_results[key])\n",
    "        elif file_format in {\"tsv\", \"xml\"}:\n",
    "            all_results.extend(\n",
    "                batch_results[1:] if file_format == \"tsv\" else batch_results\n",
    "            )\n",
    "        else:\n",
    "            all_results += batch_results\n",
    "        return all_results\n",
    "\n",
    "    def get_id_mapping_results_link(self, job_id: str) -> str:\n",
    "        response = self.session.get(f\"{API_URL}/idmapping/details/{job_id}\")\n",
    "        self.check_response(response)\n",
    "        return response.json()[\"redirectURL\"]\n",
    "\n",
    "    def decode_results(\n",
    "        self, response: requests.Response, file_format: str, compressed: bool\n",
    "    ) -> Union[Dict[str, Any], List[str], str]:\n",
    "        content = (\n",
    "            zlib.decompress(response.content, 16 + zlib.MAX_WBITS)\n",
    "            if compressed\n",
    "            else response.content\n",
    "        )\n",
    "        if file_format == \"json\":\n",
    "            return json.loads(content.decode(\"utf-8\"))\n",
    "        elif file_format == \"tsv\":\n",
    "            return content.decode(\"utf-8\").splitlines()\n",
    "        elif file_format in {\"xlsx\", \"xml\"}:\n",
    "            return [content]\n",
    "        return content.decode(\"utf-8\")\n",
    "\n",
    "    def get_xml_namespace(self, element: ElementTree.Element) -> str:\n",
    "        match = re.match(r\"\\{(.*)\\}\", element.tag)\n",
    "        return match.group(1) if match else \"\"\n",
    "\n",
    "    def merge_xml_results(self, xml_results: List[str]) -> str:\n",
    "        merged_root = ElementTree.fromstring(xml_results[0])\n",
    "        namespace = self.get_xml_namespace(merged_root[0])\n",
    "        for result in xml_results[1:]:\n",
    "            root = ElementTree.fromstring(result)\n",
    "            for child in root.findall(f\"{{{namespace}}}entry\"):\n",
    "                merged_root.append(child)\n",
    "        ElementTree.register_namespace(\"\", namespace)\n",
    "        return ElementTree.tostring(merged_root, encoding=\"utf-8\", xml_declaration=True)\n",
    "\n",
    "    def print_progress_batches(self, batch_index: int, size: int, total: int) -> None:\n",
    "        n_fetched = min((batch_index + 1) * size, total)\n",
    "        logger.info(f\"Fetched: {n_fetched} / {total}\")\n",
    "\n",
    "    def get_id_mapping_results_search(self, url: str) -> Union[Dict[str, Any], str]:\n",
    "        parsed = urlparse(url)\n",
    "        query = parse_qs(parsed.query)\n",
    "        file_format = query.get(\"format\", [\"json\"])[0]\n",
    "        size = int(query.get(\"size\", [500])[0])\n",
    "        compressed = query.get(\"compressed\", [\"false\"])[0].lower() == \"true\"\n",
    "        parsed = parsed._replace(query=urlencode(query, doseq=True))\n",
    "        url = parsed.geturl()\n",
    "\n",
    "        response = self.session.get(url)\n",
    "        self.check_response(response)\n",
    "        results = self.decode_results(response, file_format, compressed)\n",
    "        total = int(response.headers[\"x-total-results\"])\n",
    "        self.print_progress_batches(0, size, total)\n",
    "\n",
    "        for i, batch in enumerate(\n",
    "            self.get_batch(\n",
    "                self.get_next_link(response.headers), file_format, compressed\n",
    "            ),\n",
    "            1,\n",
    "        ):\n",
    "            results = self.combine_batches(results, batch, file_format)\n",
    "            self.print_progress_batches(i, size, total)\n",
    "\n",
    "        return self.merge_xml_results(results) if file_format == \"xml\" else results\n",
    "\n",
    "    def get_id_mapping_results_stream(\n",
    "        self, url: str\n",
    "    ) -> Union[Dict[str, Any], List[str]]:\n",
    "        if \"/stream/\" not in url:\n",
    "            url = url.replace(\"/results/\", \"/results/stream/\")\n",
    "        response = self.session.get(url)\n",
    "        self.check_response(response)\n",
    "        parsed = urlparse(url)\n",
    "        query = parse_qs(parsed.query)\n",
    "        file_format = query.get(\"format\", [\"json\"])[0]\n",
    "        compressed = query.get(\"compressed\", [\"false\"])[0].lower() == \"true\"\n",
    "        return self.decode_results(response, file_format, compressed)\n",
    "\n",
    "    def convert_results_to_dataframe(self, results: Dict[str, Any]) -> pd.DataFrame:\n",
    "        rows = [\n",
    "            [\n",
    "                result[\"from\"],\n",
    "                result[\"to\"][\"primaryAccession\"],\n",
    "                (\n",
    "                    result[\"to\"][\"genes\"][0][\"geneName\"][\"value\"]\n",
    "                    if result[\"to\"][\"genes\"]\n",
    "                    else None\n",
    "                ),\n",
    "                result[\"to\"][\"organism\"][\"scientificName\"],\n",
    "            ]\n",
    "            for result in results[\"results\"]\n",
    "        ]\n",
    "        return pd.DataFrame(\n",
    "            rows, columns=[\"chembal\", \"uniport_accession\", \"gene_name\", \"organism\"]\n",
    "        )\n",
    "\n",
    "    def get_dataframe_from_ids(self, ids: List[str]) -> pd.DataFrame:\n",
    "        job_id = self.submit_id_mapping(from_db=\"ChEMBL\", to_db=\"UniProtKB\", ids=ids)\n",
    "        if self.check_id_mapping_results_ready(job_id):\n",
    "            link = self.get_id_mapping_results_link(job_id)\n",
    "            results_dict = self.get_id_mapping_results_search(link)\n",
    "            return self.convert_results_to_dataframe(results_dict)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    def get_target_predictions(self, smiles: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        从ChEMBL获取目标预测。\n",
    "\n",
    "        Args:\n",
    "            smiles (str): 化合物的SMILES表示。\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: 包含目标预测结果的DataFrame。如果请求失败，返回空DataFrame。\n",
    "\n",
    "        Raises:\n",
    "            requests.exceptions.RequestException: 如果API请求失败。\n",
    "        \"\"\"\n",
    "        url = \"https://www.ebi.ac.uk/chembl/target-predictions\"\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        payload = {\"smiles\": smiles}\n",
    "        try:\n",
    "            response = self.session.post(\n",
    "                url, headers=headers, json=payload, timeout=600\n",
    "            )\n",
    "            self.check_response(response)\n",
    "            data = response.json()\n",
    "            result_df = pd.DataFrame(data)\n",
    "            result_df.insert(0, \"smiles\", smiles)\n",
    "            return result_df\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"Returning empty DataFrame for {smiles} with error: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def search_smiles(self, smiles: str) -> pd.DataFrame:\n",
    "        df_predictions = self.get_target_predictions(smiles)\n",
    "        if df_predictions.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # 保存中间过程的预测结果\n",
    "        self.all_predictions = pd.concat(\n",
    "            [self.all_predictions, df_predictions], ignore_index=True\n",
    "        )\n",
    "# 设置筛选条件\n",
    "        df_filtered = df_predictions[\n",
    "            (df_predictions[\"organism\"] == \"Homo sapiens\")\n",
    "            & ((df_predictions[\"80%\"] == \"active\") | (df_predictions[\"80%\"] == \"both\"))\n",
    "            & (df_predictions[\"threshold\"] >= 6)\n",
    "        ]\n",
    "        unique_chembl_ids = df_filtered[\"target_chemblid\"].unique().tolist()\n",
    "\n",
    "        df_genes = self.get_dataframe_from_ids(unique_chembl_ids)\n",
    "\n",
    "        # Debug: Print the structure of df_genes\n",
    "        logger.debug(f\"df_genes columns: {df_genes.columns}\")\n",
    "        logger.debug(f\"df_genes head: {df_genes.head()}\")\n",
    "\n",
    "        if not {\"chembal\", \"gene_name\"}.issubset(df_genes.columns):\n",
    "            logger.error(\n",
    "                \"Expected columns 'chembal' and 'gene_name' not found in df_genes\"\n",
    "            )\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df_genes = df_genes[[\"chembal\", \"gene_name\"]]\n",
    "\n",
    "        df_merged = pd.merge(\n",
    "            df_filtered,\n",
    "            df_genes,\n",
    "            left_on=\"target_chemblid\",\n",
    "            right_on=\"chembal\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        df_merged.drop(columns=[\"chembal\"], inplace=True)\n",
    "        # 增加一列source\n",
    "        df_merged[\"source\"] = \"chembal\"\n",
    "        df_result = self.rename_and_select(df_merged)\n",
    "        return df_result\n",
    "\n",
    "    def rename_and_select(self, data):\n",
    "\n",
    "        column_mapping = {\n",
    "            \"smiles\": \"smiles\",\n",
    "            \"gene_name\": \"targets\",\n",
    "            \"source\": \"source\",\n",
    "        }\n",
    "        if data.empty:\n",
    "            return pd.DataFrame(columns=list(column_mapping.values()))\n",
    "\n",
    "        return data.rename(columns=column_mapping)[list(column_mapping.values())]\n",
    "\n",
    "    # TODO 以后提供获取原始数据的方法\n",
    "\n",
    "\n",
    "chembl_smiles_target = ChEMBLTargetScraper().search_smiles\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 10:31:08,711 - __main__ - INFO - Fetched: 8 / 8\n",
      "2024-09-26 10:31:34,300 - __main__ - INFO - Fetched: 6 / 6\n",
      "2024-09-26 10:31:46,506 - __main__ - INFO - Fetched: 3 / 3\n",
      "2024-09-26 10:32:04,642 - __main__ - INFO - Fetched: 6 / 6\n",
      "2024-09-26 10:32:23,382 - __main__ - INFO - Fetched: 4 / 4\n",
      "2024-09-26 10:32:54,076 - __main__ - INFO - Fetched: 10 / 10\n",
      "2024-09-26 10:33:10,253 - __main__ - INFO - Fetched: 3 / 3\n",
      "2024-09-26 10:33:33,709 - __main__ - INFO - Fetched: 8 / 8\n",
      "2024-09-26 10:34:04,752 - __main__ - INFO - Fetched: 9 / 9\n",
      "2024-09-26 10:34:38,098 - __main__ - INFO - Fetched: 18 / 18\n",
      "2024-09-26 10:34:50,226 - __main__ - INFO - Fetched: 8 / 8\n",
      "2024-09-26 10:35:07,548 - __main__ - INFO - Fetched: 15 / 15\n",
      "2024-09-26 10:35:38,602 - __main__ - INFO - Fetched: 10 / 10\n",
      "2024-09-26 10:35:46,764 - __main__ - INFO - Fetched: 2 / 2\n",
      "2024-09-26 10:36:13,540 - __main__ - INFO - Fetched: 9 / 9\n",
      "2024-09-26 10:36:38,933 - __main__ - INFO - Fetched: 16 / 16\n",
      "2024-09-26 10:37:11,446 - __main__ - INFO - Fetched: 12 / 12\n",
      "2024-09-26 10:37:35,216 - __main__ - INFO - Fetched: 6 / 6\n",
      "2024-09-26 10:37:40,926 - __main__ - INFO - Fetched: 2 / 2\n",
      "2024-09-26 10:37:55,441 - __main__ - INFO - Fetched: 9 / 9\n",
      "2024-09-26 10:38:14,078 - __main__ - INFO - Fetched: 16 / 16\n",
      "2024-09-26 10:38:39,300 - __main__ - INFO - Fetched: 12 / 12\n",
      "2024-09-26 10:38:56,249 - __main__ - INFO - Fetched: 6 / 6\n",
      "2024-09-26 10:39:20,572 - __main__ - INFO - Fetched: 10 / 10\n",
      "2024-09-26 10:39:34,970 - __main__ - INFO - Fetched: 4 / 4\n",
      "2024-09-26 10:39:41,719 - __main__ - INFO - Fetched: 6 / 6\n",
      "2024-09-26 10:40:00,972 - __main__ - INFO - Fetched: 7 / 7\n",
      "2024-09-26 10:40:15,922 - __main__ - INFO - Fetched: 5 / 5\n",
      "2024-09-26 10:40:51,374 - __main__ - INFO - Fetched: 11 / 11\n",
      "2024-09-26 10:40:59,683 - __main__ - INFO - Fetched: 6 / 6\n",
      "2024-09-26 10:41:12,879 - __main__ - INFO - Fetched: 5 / 5\n",
      "2024-09-26 10:41:43,596 - __main__ - INFO - Fetched: 16 / 16\n",
      "2024-09-26 10:42:04,830 - __main__ - INFO - Fetched: 10 / 10\n",
      "2024-09-26 10:42:11,663 - __main__ - INFO - Fetched: 9 / 9\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'results/output2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     df \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39msearch_smiles(smiles)\n\u001b[1;32m     11\u001b[0m     all_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([all_results, df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mall_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results/output2/chembl.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m client\u001b[38;5;241m.\u001b[39mall_predictions\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/output2/chembl.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     16\u001b[0m )  \u001b[38;5;66;03m# 保存所有预测结果\u001b[39;00m\n\u001b[1;32m     17\u001b[0m df_result\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/output2/chembl_filtered.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     19\u001b[0m )\n",
      "File \u001b[0;32m~/projects/package/biorange/.venv/lib/python3.12/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3900\u001b[0m )\n\u001b[0;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/package/biorange/.venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1151\u001b[0m )\n\u001b[0;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/projects/package/biorange/.venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/projects/package/biorange/.venv/lib/python3.12/site-packages/pandas/io/common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 739\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/package/biorange/.venv/lib/python3.12/site-packages/pandas/io/common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    602\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'results/output2'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    client = ChEMBLTargetScraper()\n",
    "    # 读取CSV文件中的SMILES列\n",
    "    smiles_list = pd.read_csv(\n",
    "        \"/home/liuyan/projects/package/biorange/biorange/target_predict/input_data/admet_filtered_ingredients.csv\"\n",
    "    )[\"smiles\"].tolist()\n",
    "\n",
    "    all_results = pd.DataFrame()\n",
    "    for smiles in smiles_list:\n",
    "        df = client.search_smiles(smiles)\n",
    "        all_results = pd.concat([all_results, df], ignore_index=True)\n",
    "\n",
    "    all_results.to_csv(\"./results/output2/chembl.csv\", index=False)\n",
    "    client.all_predictions.to_csv(\n",
    "        \"./results/output2/chembl.csv\", index=False\n",
    "    )  # 保存所有预测结果\n",
    "    # df_result.to_csv(\n",
    "    #     \"./results/output2/chembl_filtered.csv\", index=False\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.all_predictions.to_csv(\n",
    "        \"./chembl.csv\", index=False\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 11:23:28,862 - __main__ - INFO - Fetched: 3 / 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate results for SMILES 'CCO':\n",
      "  smiles targets   source\n",
      "0    CCO   PSMB9  chembal\n",
      "1    CCO   CECR2  chembal\n",
      "2    CCO   PTPN2  chembal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 11:23:33,621 - __main__ - INFO - Retrying in 3s\n",
      "2024-09-26 11:23:48,119 - __main__ - INFO - Fetched: 3 / 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate results for SMILES 'C1=CC=CC=C1':\n",
      "        smiles targets   source\n",
      "0  C1=CC=CC=C1   CECR2  chembal\n",
      "1  C1=CC=CC=C1   PTPN1  chembal\n",
      "2  C1=CC=CC=C1   PTPN2  chembal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 11:24:00,628 - __main__ - INFO - Fetched: 3 / 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate results for SMILES 'CC(=O)O':\n",
      "    smiles targets   source\n",
      "0  CC(=O)O   PSMB9  chembal\n",
      "1  CC(=O)O   CECR2  chembal\n",
      "2  CC(=O)O   PTPN2  chembal\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'organism'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/package/biorange/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'organism'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m all_intermediate_results\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintermediate_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Apply filtering criteria on the combined results\u001b[39;00m\n\u001b[1;32m     34\u001b[0m filtered_results \u001b[38;5;241m=\u001b[39m all_intermediate_results[\n\u001b[0;32m---> 35\u001b[0m     (\u001b[43mall_intermediate_results\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morganism\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHomo sapiens\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     36\u001b[0m     ((all_intermediate_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m80\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactive\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m|\u001b[39m (all_intermediate_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m80\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m     37\u001b[0m     (all_intermediate_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m     38\u001b[0m ]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Log the filtered results\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltered results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/package/biorange/.venv/lib/python3.12/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/projects/package/biorange/.venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'organism'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Instantiate the scraper\n",
    "scraper = ChEMBLTargetScraper()\n",
    "\n",
    "# Define a list of SMILES strings to search\n",
    "smiles_list = [\n",
    "    \"CCO\",  # Ethanol\n",
    "    \"C1=CC=CC=C1\",  # Benzene\n",
    "    \"CC(=O)O\",  # Acetic acid\n",
    "]\n",
    "\n",
    "# DataFrame to store all intermediate results\n",
    "all_intermediate_results = pd.DataFrame()\n",
    "\n",
    "# Iterate through the SMILES strings\n",
    "for smiles in smiles_list:\n",
    "    # Fetch target predictions for each SMILES\n",
    "    df_predictions = scraper.search_smiles(smiles)\n",
    "    \n",
    "    # Append the current predictions to the intermediate results DataFrame\n",
    "    all_intermediate_results = pd.concat(\n",
    "        [all_intermediate_results, df_predictions], ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Log the intermediate results\n",
    "    print(f\"Intermediate results for SMILES '{smiles}':\")\n",
    "    print(df_predictions)\n",
    "\n",
    "# Save all intermediate results to a CSV file\n",
    "all_intermediate_results.to_csv(\"intermediate_results.csv\", index=False)\n",
    "\n",
    "# Apply filtering criteria on the combined results\n",
    "filtered_results = all_intermediate_results[\n",
    "    (all_intermediate_results[\"organism\"] == \"Homo sapiens\") &\n",
    "    ((all_intermediate_results[\"80%\"] == \"active\") | (all_intermediate_results[\"80%\"] == \"both\")) &\n",
    "    (all_intermediate_results[\"threshold\"] >= 6)\n",
    "]\n",
    "\n",
    "# Log the filtered results\n",
    "print(\"Filtered results:\")\n",
    "print(filtered_results)\n",
    "\n",
    "# Save the filtered results to a CSV file\n",
    "filtered_results.to_csv(\"filtered_results.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
